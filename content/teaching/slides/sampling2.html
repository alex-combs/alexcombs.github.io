<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>PADP 7120 Data Applications in PA</title>
    <meta charset="utf-8" />
    <meta name="author" content="Alex Combs" />
    <script src="sampling2_files/header-attrs-2.5/header-attrs.js"></script>
    <link href="sampling2_files/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
    <script src="sampling2_files/anchor-sections-1.0/anchor-sections.js"></script>
    <link rel="stylesheet" href="mypres.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# PADP 7120 Data Applications in PA
## Sampling
### Alex Combs
### UGA | SPIA | PADP
### Last updated: October 22, 2021

---


# Outline



- Understand what allows us to take a sample and make conclusions about a population
  - Normal distribution and standard deviation (68-95-99 rule)
  - Law of large numbers (LLN)
  - Central limit theorem (CLT)
  
- We will use R to make this as concrete as possible

&gt; **Download and open the "sampling-simulations.Rmd" on eLC.**

---
# Credible analysis

&lt;img src="lectures_files/credible.png" width="1304" style="display: block; margin: auto;" /&gt;

---
# Regression table

`$$MedHHInc = \beta_0 + \beta_1HSDegree + \beta_2 Urbanization + \epsilon$$` 




|term      | estimate| std_error| statistic| p_value| lower_ci| upper_ci|
|:---------|--------:|---------:|---------:|-------:|--------:|--------:|
|intercept |  -115383|     22643|        -5|       0|  -160935|   -69830|
|hs        |     1993|       262|         8|       0|     1465|     2521|
|urbanlow  |    -6541|      1801|        -4|       0|   -10165|    -2918|

--

- Our goal is to gain an intuitive understanding of `std_error`, `lower_ci`, and `upper_ci` columns; how they are derived and what they tell us.

---
# Inference

&lt;img src="lectures_files/sample-estimate.png" width="1363" height="90%" style="display: block; margin: auto;" /&gt;

---
# Sample estimates

- A sample estimate can be any statistical measure we are interested in:
  - Mean, median of a continuous variable
  - Proportion, percentage of levels of a categorical variable
  - Difference between two means or percentages between groups
  - Regression coefficient/estimate of `\(\beta\)`

---
# Questions of inference

- Is our estimate an accurate guess of the population parameter?
  - `\(E\)` denotes expected value; the average of our estimate over many repetitions

`$$E(\hat{\theta}) = \theta  ?$$`

- **Biased** if our estimate is systematically too high or low

--

- How precise is our estimate? Is it useful?

`$$[\hat{\theta}-?, \hat{\theta}+?]$$`

- The larger the range needed to confidently capture the parameter, the less useful it is.

---
# Inference overview

1. We take a sample. Hopefully **random**. If not, need to correct using sample weights and/or controls in a regression. Otherwise, **biased**.

--

2. **Law of large numbers (LLN)** allows us to say our sample estimate is expected to be close to the population parameter.

--

3. **Central limit theorem (CLT)** allows us to assume the **sampling distribution** of our estimate is a **normal distribution**.

--

4. We calculate the standard deviation of the sampling distribution, a.k.a. **standard error**, and construct **confidence intervals** based on the **68-95-99 rule**.

---
# Law of Large Numbers (LLN)

- We *know* a (fair) coin has 50% chance landing heads. 

- The population parameter for the number of heads for all coin flips ever is 50%.

--

- We do not know the population parameter for most phenomena

- LLN says: given a large enough sample size, our sample estimate will approach the population parameter

---
# Law of Large Numbers (LLN)

&gt; **Run the `set-up` and `functions` code chunks**

--

&gt; **Run the `coin-flips` code chunk**

--

&gt; **Run the `head-count` code chunk. Make note of the percent of flips resulting in heads.**

--

&gt; **Change the number of flips from 10 to 100 and run again. Make note of the percent of flips resulting in heads.**

---
class: inverse, center, middle

# As sample size increases, accuracy tends to increase (assuming no bias)

---
# Sampling distribution

- Our sample of 100 has revealed an estimate of the probability of heads that should be close to the parameter

- Highly unlikely that our estimate *equals* the parameter, so we need to construct a **range of plausible values** that will capture the parameter

--

- What if we collected all of the estimates we got from each of our samples and plotted their distribution? That would give us the **sampling distribution** for our estimate.

--

&gt; **Replace values in the `class-sampling-distribution` code chunk then run.**

--

&gt; **We need more estimates to make a proper histogram. Let's obtain two more estimates each and add to histogram.**

---
# Sampling distribution

- Distribution of a variable is the distribution of *values* for that variable in a given sample

- Sampling distribution is the distribution of *estimates* (e.g., proportion, average, regression coefficient) each obtained from a different sample that contains the variable(s) of interest

--

- In our coin flip example:
  - Data: 100 observations of a coin flip
  - Distribution: the distribution of heads and tails in our sample of 100
  - Estimate: percent of flips resulting in heads in our sample of 100 
  - Sampling distribution: the distribution of percent heads from all of the samples of 100 flips we simulated

---
# Central Limit Theorem

- The CLT says, no matter the shape of the underlying distribution of the variable from which our estimate was derived, its sampling distribution will be approximately normal given sufficient sample size.

--

- For a normal distribution:

  - 68% of the estimates fall within one standard deviation

  - 95% of the estimates fall within 1.96 standard deviations

  - 99% fall within 2.58 standard deviations

---
# Standard Error

- We need to know the **standard deviation of our sampling distribution**. Then we can compute a range of plausible values for our parameter.

- **Standard error** is the special name we give to the standard deviation of a sampling distribution.

&gt; **Run the `standard-error` code chunk to compute the standard error of our sampling distribution.**

---
# Confidence intervals

- **Confidence interval** is the range of plausible values that captures our population parameter.

- Common to use a 95% confidence interval: 1.96 standard errors below and above our estimate.

--

&gt; **Run the `confidence-interval` code chunk**

---
# Confidence intervals &amp; sample size

- Each of the next three code chunks uses a different sample size of coin flips (10,100,1000), counts the number of heads, then replicates this 100 times to provide you 100 *estimates* for percent heads.

--

&gt; **Run the `sampling-distribution` code chunks**

- Should notice the spread of the sampling distribution decreasing as sample size increases

--

&gt; **Run the `se` code chunks**

- The standard error should be decreasing as sample size increases

---
class: inverse, center, middle

# As sample size increases, precision increases

---
# MPA Salary Inference

- In reality, we do not have many samples to construct an actual sampling distribution.

- We just have one sample and one estimate

- Let's use inference in a more realistic way, but test its success by making a simulated population we can observe

&gt; **Run the `mpa-population` and `parameter` code chunks.**

- What is the population parameter for average salary among all MPA graduates?

---
# Sample and estimate

&gt; **Once you've been given your sample size (n), run the `sample` and `salary-estimate` code chunks.**

--

- You now have a sample of MPA graduates drawn from the population

--

- This time, we won't compile our estimates to make a sampling distribution.

- Instead, we assume our estimate is a single draw from a sampling distribution that is approximately normal even though we never observe the sampling distribution

--

- But we still need the standard error of the sampling distribution to construct confidence intervals...

---
# Standard error

- Our estimate is a sample mean. The (assumed) standard error for a sample mean is:

`$$SE_{\bar{x}}=\frac{s}{\sqrt{n}}$$`
- Where `\(s\)` is the standard deviation of `\(x\)` in our sample and `\(n\)` is the size of our sample.

--

&gt; **Run the `salary-standard-error` code chunk**

---
# Confidence intervals

- Now we need a plausible range of values that we expect to capture the parameter 95 times if this "study" was conducted 100 times

&gt; **Run the `salary-ci` and `precision` code chunks**

--

- Those with larger sample sizes should have more precise confidence intervals

- Does your confidence interval contain the population parameter?

---
# Confidence interval

A 95% confidence interval **does not** mean there is a 95% probability that it captures the parameter. It either does or it does not.

--

Rather, if we were to do this "study" 100 times, our method of constructing the 95% CI is *expected* to produce 95 successful CIs and 5 unsuccessful CIs. 

--

We saw that our one CI was successful because we knew the parameter. In reality, our CI could be one of the unsuccessful ones. But we accept this knowing that our method is expected to fail only 5 out of 100 times.

---
# A look at 100 CIs







&lt;img src="sampling2_files/figure-html/unnamed-chunk-9-1.png" style="display: block; margin: auto;" /&gt;


---
# Point estimate vs. CI

- Suppose our estimate for average salary was $81,053. This is what often gets reported. This is for brevity and convenience.

--

- The point estimate **does not** represent the most likely value for the parameter within the CI. No value within the CI is more or less likely to represent the parameter.

--

- Assuming we have a successful CI, the parameter could fall **anywhere** within it, including the lower and upper bounds.

--

- Depending on the context of our study and the width of the CI, only reporting the point estimate could be very misleading.

--

- What if the 95% CI for average salary was [20,000 - 140,000]?

---
# Back to regression table

`$$MedHHInc = \beta_0 + \beta_1HSDegree + \beta_2 Urbanization + \epsilon$$` 


|term      |   estimate| std_error| statistic| p_value|    lower_ci|   upper_ci|
|:---------|----------:|---------:|---------:|-------:|-----------:|----------:|
|intercept | -115382.50| 22643.377|    -5.096|   0.000| -160935.103| -69829.905|
|hs        |    1993.18|   262.416|     7.595|   0.000|    1465.267|   2521.093|
|urbanlow  |   -6541.47|  1801.233|    -3.632|   0.001|  -10165.082|  -2917.857|

- Now we can apply the concepts to our regression table
- We took one sample of state data
- Obtained estimates for `\(\beta\)`s (similar to sample mean; different math)
- **LLN** and **CLT** allow us to assume each estimate is close to the parameter and is drawn from a sampling distribution that is normal

---
# Back to regression table


|term      | estimate| std_error| statistic| p_value| lower_ci| upper_ci|
|:---------|--------:|---------:|---------:|-------:|--------:|--------:|
|intercept |  -115383|     22643|        -5|       0|  -160935|   -69830|
|hs        |     1993|       262|         8|       0|     1465|     2521|
|urbanlow  |    -6541|      1801|        -4|       0|   -10165|    -2918|

- Therefore, we calculate the standard error (similar to before but math is different)
- Then calculate the lower and upper bounds of the 95% CI

---
# Back to the regression table


|term      | estimate| std_error| statistic| p_value| lower_ci| upper_ci|
|:---------|--------:|---------:|---------:|-------:|--------:|--------:|
|intercept |  -115383|     22643|        -5|       0|  -160935|   -69830|
|hs        |     1993|       262|         8|       0|     1465|     2521|
|urbanlow  |    -6541|      1801|        -4|       0|   -10165|    -2918|

- Report on the point estimate for `hs` would be something like "On average, as the percent of a state's population with at least a high school degree increases 1 percentage point, median household income tends to increase almost 2,000 dollars."

- Assuming this estimate is unbiased, it is still just one possible value for the *true* value of `\(\beta_1\)`

---
# Back to the regression table


|term      | estimate| std_error| statistic| p_value| lower_ci| upper_ci|
|:---------|--------:|---------:|---------:|-------:|--------:|--------:|
|intercept |  -115383|     22643|        -5|       0|  -160935|   -69830|
|hs        |     1993|       262|         8|       0|     1465|     2521|
|urbanlow  |    -6541|      1801|        -4|       0|   -10165|    -2918|


```r
# not equal due to rounding
1993 - 1.96*262
```

```
## [1] 1479.48
```

```r
1993 + 1.96*262
```

```
## [1] 2506.52
```

---
# Back to the regression table


|term      | estimate| std_error| statistic| p_value| lower_ci| upper_ci|
|:---------|--------:|---------:|---------:|-------:|--------:|--------:|
|intercept |  -115383|     22643|        -5|       0|  -160935|   -69830|
|hs        |     1993|       262|         8|       0|     1465|     2521|
|urbanlow  |    -6541|      1801|        -4|       0|   -10165|    -2918|

- `\(\beta_1\)` could fall anywhere in the 95% CI with equal likelihood

- So we might want to say, "On average, as the percent of a state's population with at least a high school degree increases 1 percentage point, median household income tends to increase between 1,500 and 2,500 dollars."

- Remember, precision can be used to make us more confident in an answer than we should be.

---
# Back to the regression table


|term      | estimate| std_error| statistic| p_value| lower_ci| upper_ci|
|:---------|--------:|---------:|---------:|-------:|--------:|--------:|
|intercept |  -115383|     22643|        -5|       0|  -160935|   -69830|
|hs        |     1993|       262|         8|       0|     1465|     2521|
|urbanlow  |    -6541|      1801|        -4|       0|   -10165|    -2918|

- Even still, our sample could be one of the 5 out of 100 samples where our method of inference is expected to fail to capture `\(\beta_1\)`.

- We could lower this frequency by reporting a 99% CI...

---
# Back to the regression table


|term      | estimate| std_error| statistic| p_value| lower_ci| upper_ci|
|:---------|--------:|---------:|---------:|-------:|--------:|--------:|
|intercept |  -115383|     22643|        -5|       0|  -160935|   -69830|
|hs        |     1993|       262|         8|       0|     1465|     2521|
|urbanlow  |    -6541|      1801|        -4|       0|   -10165|    -2918|


```r
1993-2.58*262
```

```
## [1] 1317.04
```

```r
1993+2.58*262
```

```
## [1] 2668.96
```

---
# Final points for consumers

- Beware a point estimate without a confidence interval

--

- Sample size improves the accuracy of the estimate settling on parameter

--

- Sample size improves the precision of the CI

--

- The worse our regression fits the data (i.e. lower `\(R^2\)` or higher RMSE), the larger the standard error and thus less precise our CI
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="macros.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
