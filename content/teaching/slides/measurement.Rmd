---
title: "PADP 7120 Data Applications in PA"
subtitle: "Measurement Validity & Reliability"
author: "Alex Combs"
institute: "UGA | SPIA | PADP"
date: "Last updated: `r format(Sys.time(), '%B %d, %Y')`"
output:
  xaringan::moon_reader:
    css: 'mypres.css'
    nature:
      beforeInit: "macros.js"
      highlightStyle: github
      countIncrementalSlides: false
---
# Outline

- Introduction to the building blocks of credible analysis

- Measurement validity

- Measurement reliability

---
# Credible analysis

![](lectures_files/credible.png)

---
class: inverse, middle, center

# All data is a measured representation of reality.

---
# Measurement

- **Measurement Validity**: Does the variable measure the concept/phenomenon it is intended or claims to measure? Are the recorded values of the variable accurate measures of the true values of the variable?

--

- **Measurement Reliability**: Provided no change in a subjectâ€™s condition/reality, does the way the variable is measured generate the same value? Given identical conditions/realities between multiple subjects, does the measure generate identical values?

---
# Measurement

![](lectures_files/measure_lines.png)

---
class: inverse, middle, center

# In your groups, settle on a variable and discuss its measurement validity and reliability. Be ready to discuss with class.

---
# Why does this matter?

- Often leads to important and interesting questions about how data is collected and whether it is trustworthy.

- If data have a weak or no relationship with the thing you are trying to study, you have no foundation upon which to continue your work.

- Sometimes flawed data is all we have, and understanding its flaws can help mitigate mistakes in interpretations and decisions.

---
class: inverse, middle, center

# Missing data

---
# Missing Data

- Two types
  - Explicit
  - Implicit
  
- Explicitly missing data are data that we can *see* are missing in the data; cells containing a value that denotes missing

- Implicitly missing data are data that we would expect to be included based on data structure but are not; no obvious sign of missing

---
# Explicitly missing

```{r, echo=FALSE, message=FALSE}
library(gapminder)
library(tidyverse)
library(knitr)

crossgap <- gapminder %>% 
  filter(year == 2007 & continent == 'Americas') %>% 
  head(n=3)

crossgap[1,4] <- NA
crossgap[2,6] <- NA

kable(crossgap, format = 'html', digits = 1)
```

--

- Conceptual concerns
  - Do not assume data are missing at random
  - Ask yourself why data are missing and if it is influenced by a factor that is relevant to your analysis

--
- Technical concern
  - When describing data, account for missing values
  - Incorrect to say we have 3 countries with a mean life expectancy of `r mean(crossgap$lifeExp, na.rm=TRUE)`

---
# Implicitly missing

```{r, echo=FALSE}
gapminder %>% 
  filter(continent == 'Americas', year >= 1997) %>% 
  head(n=6) %>%
  filter(country!='Bolivia' | year!=2002) %>% 
  kable(format = 'html', digits = 1)
```

- Typical in panel data where units enter and exit the data
- Same concerns apply

---
# Precision

- Measurement validity involves accuracy. 

- Measurement reliability involves a version of precision.

--

- Another version of precision involves the exactness of a measurement, which many may associate with accuracy.

---
background-image: url(lectures_files/ruler.jpg)

# Precision

---
# Precision

```{r, echo=FALSE}
head(gapminder, n=3) %>% 
  kable(format = 'html', digits = 1)
```

- Life expectancy is reported to the nearest tenth decimal place.

- But the underlying value for life expectancy could have been anything that rounds to the tenth decimal we see in the data.

--

- What was the possible life expectancy in Afghanistan in 1952?

--

- What if five deaths at 28, 29, 29, 29, 29?

---
# Why does this matter?

- 14.38% of all statistics are lies

--

- Precision can be used to mislead people that information is accurate; a cognitive bias known as precision bias

--

- Be careful reporting numbers that are more precise than the underlying data

- May be legitimate reasons to round to fewer decimal places than underlying data, but understand you are decreasing precision

