---
title: "PADP 7120 Data Applications in PA"
subtitle: "Hypothesis Testing"
author: "Alex Combs"
institute: "UGA | SPIA | PADP"
date: "Last updated: `r format(Sys.time(), '%B %d, %Y')`"
output:
  xaringan::moon_reader:
    css: 'mypres.css'
    nature:
      beforeInit: "macros.js"
      highlightStyle: github
      countIncrementalSlides: false
---
# Outline

```{r, include=FALSE}
library(tidyverse)
library(moderndive)
library(fivethirtyeight)
library(infer)
library(knitr)
set.seed(123)
options(scipen = 999)

state_trump <- hate_crimes %>%
  mutate(share_white = 1 - share_non_white,
         urbanization = if_else(share_pop_metro<=0.75, "low", "high")) %>% 
  select(state, 
         median_house_inc, 
         share_pop_hs, 
         share_white, 
         share_white_poverty, 
         share_vote_trump,
         urbanization) %>%
  filter(state != "District of Columbia") %>% 
  mutate_at(vars(share_pop_hs, share_white, share_white_poverty,
              share_vote_trump), funs(.*100)) %>% 
  select(med_inc = median_house_inc, hs = share_pop_hs, urban = urbanization)
```

- Hypothesis testing
- p-values
- Null distribution
- Reporting statistically significant results
- Practical significance

---
# Regression table

$$MedHHInc = \beta_0 + \beta_1HSDegree + \beta_2 Urbanization + \epsilon$$ 

```{r, include=FALSE}
inc_mod <- lm(med_inc ~ hs + urban, 
              data = state_trump)
```

```{r, echo=FALSE}
get_regression_table(inc_mod) %>% 
  kable(digits = 0)
```

- Our goal is to better understand the `statistic` (less important) and `p_value` columns. 

---
class: inverse, center, middle

# What is a hypothesis test & p-value?

---
# Hypotheses and p-values

**Hypothesis test** asks the following question: "Is my result so unlikely that I can conclude with a sufficient level of confidence that there is evidence in support of my hypothesis?"

**p-value:** the probability of obtaining my result or more extreme in a world where the **null hypothesis** is actually true.

- The p-value enables us to answer the hypothesis test

---
# Structure of hypothesis test

- Alternative hypothesis $H_A$

  - Claims there is evidence for the phenomenon you are interested in testing.

--

- Null hypothesis $H_0$

  - Claims there is no evidence; the opposite of the alternative

---
# Example

```{r, echo=FALSE, fig.align='center', fig.height=5}
ggplot(promotions, aes(x = gender, fill = decision)) +
  geom_bar() +
  labs(title = "Observed Promotions", 
       x = "Gender of name on resume")
```

> **Run the all code chunks down to and including `promo-estimates`**

---
# Example

- Descriptive:

  - For our one sample, we have calculated the proportion of males promoted $p_M=0.88$ and proportion of females promoted $p_F=0.58$
  - In this sample, the difference in proportion promoted is $p_M-p_F= 0.88-0.58=0.3$ or 30 percentage points.

--

- Inference:

  - This is a sample of an unobserved population
  - And/or the counterfactual is unobservable
  - This sample provides us estimates of $P_M$, $P_F$, and $P_M-P_F$

---
# Example

What are our null and alternative hypotheses for this analysis?

$H_A$:  


$H_0$: 

---
# Hypothesis test conclusion

- What are the possible conclusions of a hypothesis test?

---
# Example

1. If results reject the null, then

  - We found statistically significant evidence that $P_M-P_F \neq 0$
  - Means the result of 0.3 is too improbable to be due to random noise

--

2. If results fail to reject the null
  - We did not find statistically significant evidence that $P_M-P_F \neq 0$
  - Means result of 0.3 is not improbable enough
  - $P_M-P_F\lesseqqgtr0$ ; we don't know which
  
--

- Can *never* conclude males and females *are* promoted equally $P_M-P_F = 0$ from a hypothesis test. This is equivalent to accepting the null.

---
# Hypothesis test conclusions

```{r, echo=FALSE, fig.align='center'}
include_graphics('lectures_files/hypotest-tables.png')
```

---
# What If We're Wrong

- Suppose our estimate of $P_M-P_F=?$, $p_M-p_F=0.3$, is so unlikely that we reject the null 

- Conclude that males and females are not promoted in equal proportions $P_M-P_F \neq 0$.

--

- Our estimate of 0.3 is a scientific guess around which we construct a range of plausible values we assume captures the parameter

--

- Our confidence interval could be 1 of the 5 out of 100 (assuming 95% CI) expected to fail to capture the parameter

---
# What If We're Wrong

- We may reject the null because our 95% CI does **not** contain 0, thus $P_M-P_F \neq 0$

--

- But our CI could be wrong and the true value is that $P_M-P_F = 0$
  - Type I error
  - False positive

---
# What If We're Wrong

- We may fail to reject the null because our 95% CI does include 0, thus we can't rule out with high enough confidence that $P_M-P_F \neq 0$

--

- But our CI could be wrong and the true value is that $P_M-P_F \neq 0$
  - Type II error
  - False negative

---
# Decision rule

- Common to choose a **significance level** of 5%, which is the same as choosing a **confidence level** of 95%.

  - Sometimes denoted $\alpha = 0.05$ where $\alpha$ is significance level

--

- If p-value is less than 0.05, we **reject** the null. If it is greater than or equal to 0.05, we **fail to reject** the null.

- If p-value $<\alpha$, reject $H_0$

- If p-value $\geq \alpha$, fail to reject $H_0$

---
class: inverse, center, middle

# How do we know the probability of our result in a null world with one sample and not knowing if we live in a world where the null is true or not?

---
# Null distribution

```{r, echo=FALSE, fig.align='center', out.height='66%'}
include_graphics('lectures_files/nulldist.png')
```

- We assume a null distribution, similar to the sampling distribution

- Null distribution is centered at 0 as if null were actually true

- Assuming null distribution is normal, we can then calculate the probability of our result

---
# Example

- If the null were true, then promotions would be random with respect to gender

  - On average, $P_M-P_F = 0$
  - Promotions and gender would share no correlation

--

- Let's use R to simulate a world where the null is true.

> **Run all code chunks down to and including `null-estimate`**

---
# Example

- Let's repeat this random shuffling 1,000 times, calculating the difference in promotions between males and females each time.

- Then we could plot the 1,000 values as a histogram, giving us a distribution of differences between males and females in a world where promotions are random with respect to gender

> **Run `null-distribution` code chunk**

---
# Null distribution

- The **LLN** tells us the center of the null distribution will settle around 0, and the **CLT** tells us that the null distribution will be normal just like the sampling distribution.

- Therefore, we can calculate the percent of values expected to fall outside some chosen number of standard errors by applying the **68-95-99 rule** to the null distribution.

--

> **Run `null-center`, `null-se`, and `null-ci` code chunks.**

---
# Example p-value

- Our observed difference was 0.29

- How likely is this result if the null were actually true?

> **Run `p-value-viz` and `p-value` code chunks**

---
# Chi-square test

- A typical analysis does not simulate a null hypothesis to obtain the p-value

- Instead, statistical tests that use standard theoretical formulas are used

--

- We have two nominal variables to test $\rightarrow$ Chi-square test

> **Run the `cross-tab` and `chi-square` code chunks**

- Does our conclusion change?

---
# Using an LPM

- We *could* use regression (LPM) for this

> **Run the `lpm` code chunk**

- Does our conclusion change?

--

- Note the estimate is the same but p-value differs. This case pushes the limits of when a regression is appropriate to use.

- But if we wanted to control for additional variables, such as age or years employed, we are back to needing a regression model.

---
# Back to regression table

```{r, echo=FALSE}
get_regression_table(inc_mod) %>% 
  kable(digits = 3)
```

- What are the null and alternative hypotheses? What is the result of the test?

- How many standard errors are our estimates from the center of the null distribution?

- What is the probability of obtaining our estimates or more extreme in a world where the null is true?

---
# Back to regression table

```{r, echo=FALSE}
get_regression_table(inc_mod) %>% 
  kable(digits = 3)
```

There is statistically significant evidence that high school attainment is positively associated with median income in states. On average, state median income increases approximately 1,993 dollars per 1 percentage point increase in the population with at least a high school degree, controlling for urbanicity. Using 95% confidence intervals, a 1 p.p. increase in high school attainment is associated with an increase of median income between 1,465 and 2,521. 

---
class: inverse, center, middle

# Practical significance

---
# Practical significance questions

1. What is the typical change in the explanatory variable associated with the statistically significant estimate?

--

2. Is the predicted change in the outcome due to a typical change in the explanatory variable meaningful?

--

3. Do the bounds of the confidence interval for the explanatory variable potentially change my answer?

--

- What is considered a meaningful change is somewhat subjective.
  
---
# Example 1

```{r, echo=FALSE, fig.align='center', out.height='33%', out.width='66%'}
include_graphics('lectures_files/prac-sig1.png')
```

- Is the property tax result practically significant?

--

- Typical change (standard deviation) in property tax is $4

--

- Predicted change in average rent from a 1 SD increase in property tax is $400 (4 X 100), or at least 240 (4 X 60).

--

- At least a 24% increase relative to the mean of rent (240/1000) and 120% of SD in rent (240/200). Practically significant.

---
# Example 2

```{r, echo=FALSE, fig.align='center', out.height='33%', out.width='66%'}
include_graphics('lectures_files/prac-sig2.png')
```

- SD for property tax is now 0.04 instead of 4

- Is the property tax result practically significant?

--

- Predicted change in average rent from 1 SD increase in property tax = $4. Not practically significant.

- Based on confidence interval, max increase is $5.60. Probably not meaningful.

---
# Example 3

```{r, echo=FALSE, fig.align='center', out.height='33%', out.width='66%'}
include_graphics('lectures_files/prac-sig3.png')
```

- SD of property tax back to 4. Predicted change same as in Example 1: $400

- But confidence interval has changed. Is the property tax result practically significant?

--

- Effect of a 1 SD increase in property tax could be as small as $8. Practical significance could be questioned in this case.

---
# Example 4

```{r, echo=FALSE, fig.align='center', out.height='33%', out.width='66%'}
include_graphics('lectures_files/prac-sig4.png')
```

- Estimate and CI for property tax has changed

- Is the property tax result practically significant?

--

- Result is statistically insignificant. Effect of property tax is anywhere between -40 and 60, including 0. 
--

- Lack of statistical significance usually means lack of practical significance. However...

---
# Example 5

```{r, echo=FALSE, fig.align='center', out.height='33%', out.width='66%'}
include_graphics('lectures_files/prac-sig5.png')
```

- Estimate and CI has changed again

--

- Even though statistically insignificant, the CI is very precise around 0.

- A 1 SD increase in property tax ranges between -2.40 and 10.40 dollars. Plausible values do not translate to a meaningful change in average rent. This is still useful.

---
# Practical significance from PS3

```{r, include=FALSE}
sum.ps3 <- arsenal::tableby(~ med_inc + hs, data = state_trump)
```

```{r, echo=FALSE, results='asis'}
summary(sum.ps3, digits=0)
```

```{r, echo=FALSE}
get_regression_table(inc_mod) %>% 
  kable(digits = 3)
```

