---
title: "PADP 7120 Data Applications in PA"
subtitle: "Hypothesis Testing"
author: "Alex Combs"
institute: "UGA | SPIA | PADP"
date: "Last updated: `r format(Sys.time(), '%B %d, %Y')`"
output:
  xaringan::moon_reader:
    css: 'mypres.css'
    nature:
      beforeInit: "macros.js"
      highlightStyle: github
      countIncrementalSlides: false
---
# Outline

```{r, include=FALSE}
library(tidyverse)
library(moderndive)
library(fivethirtyeight)
library(infer)
library(knitr)
set.seed(123)
options(scipen = 999)

state_trump <- hate_crimes %>%
  mutate(share_white = 1 - share_non_white,
         urbanization = if_else(share_pop_metro<=0.75, "low", "high")) %>% 
  select(state, 
         median_house_inc, 
         share_pop_hs, 
         share_white, 
         share_white_poverty, 
         share_vote_trump,
         urbanization) %>%
  filter(state != "District of Columbia") %>% 
  mutate_at(vars(share_pop_hs, share_white, share_white_poverty,
              share_vote_trump), funs(.*100)) %>% 
  rename(med_inc = median_house_inc, hs = share_pop_hs, urban = urbanization)
```

- Hypothesis testing
- p-values
- Null distribution
- Reporting statistically significant results
- Practical significance

---
# Regression table

$$MedHHInc = \beta_0 + \beta_1HSDegree + \beta_2 Urbanization + \epsilon$$ 

```{r, include=FALSE}
inc_mod <- lm(med_inc ~ hs + urban, 
              data = state_trump)
```

```{r, echo=FALSE}
get_regression_table(inc_mod) %>% 
  kable(digits = 0)
```

- Our goal is to better understand the `statistic` (less important) and `p_value` columns. 

---
class: inverse, center, middle

# What is a hypothesis test & p-value?

---
# Hypotheses and p-values

**Hypothesis test:** "Is my result so unlikely that I can conclude with a sufficient level of confidence that there is evidence in support of my hypothesis?"

**p-value:** the probability of obtaining my result or more extreme in a world where the **null hypothesis** is actually true.

- The p-value helps us answer the hypothesis test

---
# Structure of hypothesis test

- Alternative hypothesis $H_A$

  - Claims there is evidence for the phenomenon you are interested in testing.

--

- Null hypothesis $H_0$

  - Claims there is no evidence; the opposite of the alternative

---
# Example

```{r, echo=FALSE, fig.align='center', fig.height=5}
ggplot(promotions, aes(x = gender, fill = decision)) +
  geom_bar() +
  labs(title = "Observed Promotions", 
       x = "Gender of name on resume")
```

> **Run the all code chunks down to `promo-estimates`**

---
# Example

- Descriptive:

  - For our one sample, we have calculated the proportion of males promoted $p_M=0.88$ and proportion of females promoted $p_F=0.58$
  - In this sample, the difference in proportion promoted is $p_M-p_F= 0.88-0.58=0.3$ or 30 percentage points.

--

- Inference:

  - This is a sample of an unobserved population
  - And/or the counterfactual is unobservable
  - This sample provides us estimates of $P_M$, $P_F$, and $P_M-P_F$

---
# Example

$H_A$:  


$H_0$: 

---
# Hypothesis test conclusion

- What are the possible conclusions of a hypothesis test?

---
# Example

1. If results reject the null, then

  - We found statistically significant evidence that $P_M-P_F \neq 0$
  - Result of 0.3 is too improbable to be random noise

--

2. If results fail to reject the null
  - We did not find statistically significant evidence that $P_M-P_F \neq 0$
  - Result of 0.3 is not improbable enough
  - $P_M-P_F\lesseqqgtr0$ ; we don't know which
  
--

- Can *never* conclude males and females *are* promoted equally $P_M-P_F = 0$ from a hypothesis test. This is equivalent to accepting the null.

---
# Hypothesis test conclusions

```{r, echo=FALSE, fig.align='center'}
include_graphics('lectures_files/hypotest-tables.png')
```

---
# What If We're Wrong

- Suppose our estimate, $p_M-p_F=0.3$, of $P_M-P_F=?$ is so unlikely that we reject the null 

- Conclude that males and females are not promoted in equal proportions $P_M-P_F \neq 0$.

--

- Our estimate is a scientific guess around which we construct a range of plausible values we assume captures the parameter

--

- Our confidence interval could be 1 of the 5 out of 100 (assuming 95% CI) expected to fail to capture the parameter

---
# What If We're Wrong

- We may reject the null because our 95% CI does **not** contain 0, thus $P_M-P_F \neq 0$

--

- But our CI could be wrong and the true value is that $P_M-P_F = 0$
  - Type I error
  - False positive

---
# What If We're Wrong

- We may fail to reject the null because our 95% CI does include 0, thus we can't rule out with high enough confidence that $P_M-P_F \neq 0$

--

- But our CI could be wrong and the true value is that $P_M-P_F \neq 0$
  - Type II error
  - False negative

---
# Decision rule

- Common to choose a **significance level** of 5%, which is the same as choosing a **confidence level** of 95%.

  - Sometimes denoted $\alpha = 0.05$ where $\alpha$ is significance level

--

- If p-value is less than 0.05, we **reject** the null. If it is greater than or equal to 0.05, we **fail to reject** the null.

- If p-value $<\alpha$, reject $H_0$

- If p-value $\geq \alpha$, fail to reject $H_0$

---
class: inverse, center, middle

# How do we know the probability of our result in a null world with one sample and not knowing if we live in a world where the null is true or not?

---
# Null distribution

```{r, echo=FALSE, fig.align='center', out.height='66%'}
include_graphics('lectures_files/nulldist.png')
```

- We assume a null distribution, similar to the sampling distribution

- Null distribution is centered at 0 as if null were actually true

- Assuming null distribution is normal, we can then calculate the probability of our result

---
# Example

- If the null were true, then promotions would be random with respect to gender

  - On average, $P_M-P_F = 0$
  - Promotions and gender would share no correlation

--

- Let's use R to simulate a world where the null is true.

> **Run all code chunks down to `null-estimate`**

---
# Example

- Let's repeat this random shuffling 1,000 times, calculating the difference in promotions between males and females each time.

- Then we could plot the 1,000 values as a histogram, giving us a distribution of differences between males and females in a world where promotions are random with respect to gender

> **Run `null-distribution` code chunk**

---
# Null distribution

- The **LLN** tells us the center of the null distribution will settle around 0, and the **CLT** tells us that the null distribution will be normal just like the sampling distribution.

- Therefore, we can calculate the percent of values expected to fall outside some chosen number of standard errors by applying the **68-95-99 rule** to the null distribution.

--

> **Run `null-center`, `null-se`, and `null-ci` code chunks.**

---
# Example p-value

- Our observed difference was 0.3! How likely is this result if the null were actually true?

> **Run `p-value-viz` and `p-value` code chunks**

---
# Back to regression table

```{r, echo=FALSE}
get_regression_table(inc_mod) %>% 
  kable(digits = 3)
```

- What are the null and alternative hypotheses? What is the result of the test?

- How many standard errors are our estimates from the center of the null distribution?

- What is the probability of obtaining our estimates or more extreme in a world where the null is true?

---
# Back to regression table

```{r, echo=FALSE}
get_regression_table(inc_mod) %>% 
  kable(digits = 3)
```

There is statistically significant evidence that high school attainment is positively associated with median income in states. On average, state median income increases approximately 1,993 dollars per 1 percentage point increase in the population with at least a high school degree, all else equal. With 95% confidence, a 1 p.p. increase in high school attainment is associated with an increase of median income between 1,465 and 2,521 dollars. 
