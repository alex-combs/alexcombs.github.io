---
title: "PADP 7120 Data Applications in PA"
subtitle: "Simple & Multiple Regression"
author: "Alex Combs"
institute: "UGA | SPIA | PADP"
date: "Last updated: `r format(Sys.time(), '%B %d, %Y')`"
output:
  xaringan::moon_reader:
    css: 'mypres.css'
    nature:
      beforeInit: "macros.js"
      highlightStyle: github
      countIncrementalSlides: false
      highlightLines: true
---
# Outline

```{r, include=FALSE}
library(carData)
library(openintro)
library(tidyverse)
library(moderndive)
library(knitr)
```

- Understand the purpose of regression and its relevance to making decisions

- Interpret regression coefficients

- Assess goodness-of-fit for one model or between several competing models

- Understand what it means to control for other variables

---
# Correlation coefficients

```{r}
select(States, -region) %>% 
  cor()
```

---
# Visualizing correlation

```{r, message=FALSE, fig.height=5, fig.width=6, fig.align='center'}
ggplot(States, aes(x = dollars, y = SATM)) +
  geom_point() +
  labs(x = 'Public ed spending in $1000s per student',
       y = 'Average SAT Math score')
```

---
# Correlation conclusions

```{r, echo=FALSE, message=FALSE, fig.height=5, fig.width=6, fig.align='center'}
ggplot(States, aes(x = dollars, y = SATM)) +
  geom_point() +
  labs(x = 'Public ed spending in $1000s per student',
       y = 'Average SAT Math score')
```

- States that spend more on public education tend to have lower average SAT Math scores among its graduating high school students

- The strength of the relationship is moderate at -0.48

---
# Basic purpose of regression

.pull-left[
```{r, echo=FALSE, message=FALSE}
ggplot(States, aes(x = dollars, y = SATM)) +
  geom_point() +
  geom_smooth(method = 'lm', se = FALSE) +
  labs(x = 'Public ed spending in $1000s per student',
       y = 'Average SAT Math score') +
  theme_minimal() +
  theme(text = element_text(size=16))
```
]

.pull-right[
- Regression gives us direction, strength, and magnitude of association
- Draws the line of **best fit** through a set of paired x-y data points
- The slope of the line tells us the **average, predicted change in y given a change in x**, or
- At any value along x-axis, regression line gives us the **predicted value of y**
]

---
# Basic purpose of regression

- Fill in the blanks: Regression can be used to [    ] an outcome or [    ] an outcome, or both.

--

- Either way, regression is a way of modeling an outcome $y$ as a function of explanatory $x$

---
# Adding a regression line

```{r, message=FALSE, fig.height=5, fig.width=6, fig.align='center'}
ggplot(States, aes(x = dollars, y = SATM)) +
  geom_point() +
  geom_smooth(method = 'lm', se = FALSE) + #<<
  labs(x = 'Public ed spending in $1000s per student',
       y = 'Average SAT Math score')
```

---
# Equation of a line

$$y = 600 - 20x$$

- If $x=5$, $y=?$

- If $x=6$, $y=?$

--

- If $x$ increases from 5 to 6, by how much does $y$ change?

- If $x$ increases from 2 to 5, by how much does $y$ change?

---
# Simple linear regression model

$$y=\beta_0+\beta_1x+\epsilon$$

- Which represents the dependent variable?
- Which represents the independent variable?
- Which represents the unknown population parameters?
- Which represents statistical noise?

---
# Simple linear regression model

$$\hat{y}=b_0+b_1x$$

- Which represents the predicted outcome?
- Which represents the estimates?

---
# Example: Population to sample models

- Suppose we want to model average SAT math scores, `SATM`, in a state as a function of its spending on public education in **$1000s per student**, `dollars`

$$SATM=\beta_0+\beta_1Dollars+\epsilon$$

--

```{r, echo=FALSE}
satm_mod1 <- lm(SATM ~ dollars, data = States)
get_regression_table(satm_mod1) %>% 
  kable(format = 'html')
```

--

$$\hat{SATM} = 560 - 12 \times Dollars$$

---
# Example: Reporting results

$$\hat{SATM} = 560 - 12 \times Dollars$$

**On average**, a **one thousand dollar increase** in **state spending on public education per student** is *associated with* a **12 point decline** in **average SAT math scores**.

--

- What is the predicted increase in `SATM` if a state increased `Dollars` by $2,500 per student?

--

- What is the predicted `SATM` in a state that spends $5,000 per student?

--

- What is the predicted `SATM` in a state that spends $0 per student?

---
# Another example

- Now `SATM` as a function of the percent of graduating high school students who take the SAT, `percent`

$$SATM=\beta_0+\beta_1Percent+\epsilon$$
```{r, echo=FALSE}
satm_mod2 <- lm(SATM ~ percent, data = States)
get_regression_table(satm_mod2) %>% 
  kable(format = 'html')
```

$$\hat{SATM} = 539 - 1.2 \times Percent$$

- Now we can consider any hypothetical *change* in percent or specific *value* of percent and provide a prediction for SAT math scores.

---
# Change vs. value
$$\hat{SATM} = 539 - 1.2 \times Percent$$
.pull-left[
What if percent taking SAT increased from 50% to 55%?

]

--

.pull-right[
What is the predicted average SAT math score for a state where 75% of high school graduates take the SAT?

]

---
# More practice

$$\hat{SATM} = 539 - 1.2 \times Percent$$

- What is the predicted average SAT math score in a state where 25% of its high school graduates take the SAT?
- What is the predicted average SAT math score in a state where 100% of its high school graduates take the SAT?
- What is the predicted change in average SAT math score in a state where the percent of high school graduates taking the SAT increases 75 percentage points?

---
class: inverse, middle, center

# Make sure you understand the difference between a percent change and a percentage point change.

---
class: inverse, middle, center

# Running regressions in R

---
# Running regression

- Explore data

```{r}
glimpse(States)
```

---
# Running regression

```{r, out.width=8}
filter(States, -region) %>% 
summary()
```

---
# Running regression

```{r, eval=FALSE}
satm_mod1 <- lm(SATM ~ dollars, data = States)
satm_mod2 <- lm(SATM ~ percent, data = States)
```

```{r, eval=FALSE}
library(moderndive)
get_regression_table(satm_mod1)
```
```{r, echo=FALSE}
get_regression_table(satm_mod1) %>% 
  kable()
```

---
# Recap of population and sample regressions

**Population Model**

$$y=\beta_0+\beta_1x+\epsilon$$

$$SATM=\beta_0+\beta_1Dollars+\epsilon$$

**Sample Model**

$$\hat{y}=b_0+b_1x$$
$$\hat{SATM} = 560 - 12 \times Dollars$$

---
class: inverse, center, middle

# What happens to that error term, $\epsilon$, when we move to the sample model?

---
# The residual

$$e=y-\hat{y}$$

- The residual is the difference between the *observed* outcome $y$ and the *predicted* outcome $\hat{y}$ in our regression model

- The residual is the sample statistic of the population parameter $\epsilon$

```{r, include=FALSE}
satm_mod1.metrics <- broom::augment(satm_mod1)

viz.resid <- ggplot(satm_mod1.metrics, aes(x = dollars, y = SATM)) +
  geom_point(color = 'steelblue') +
  geom_smooth(method = 'lm', se = FALSE) +
  geom_segment(aes(xend = dollars, yend = .fitted), color = "red", size = 0.3) +
  labs(x = 'Public ed spending in $1000s per student',
       y = 'Average SAT Math score') +
  theme_classic()
```


```{r, echo=FALSE, message=FALSE, fig.align='center', fig.height=5, fig.width=6}
viz.resid
```

---
# Residuals

$$\hat{SATM} = 560 - 12 \times Dollars$$

- What is the predicted `SATM` for a state where `dollars` equals $7,887? 

- How about a state where `dollars` equals $4,231?

--

- If these values for `dollars` are actually observed in the data, we can also check what `SATM` actually equaled. Our regression model will either overestimate or underestimate that actual value of `SATM`.

---
# Examining residuals

```{r, eval=FALSE}
get_regression_points(satm_mod1)
```

- Regression results for each observation

- Shows observed data, predicted outcomes, and residuals

```{r, echo=FALSE}
get_regression_points(satm_mod1) %>% 
  head(n=6) %>% 
  kable(format = 'html')
```

---
class: inverse, center, middle

# Regression draws the line of best fit through observed x-y pairs. What does best fit mean?

---
# Ordinary least squares (OLS)

- Standard regression is also known as OLS

- Regression uses math you don't need to worry about to determine the intercept and slope of a line that **minimizes the sum of squared residuals (SSR)**

---
# OLS

.pull-left[
```{r, echo=FALSE, message=FALSE}
viz.resid
```
]

.pull-right[
```{r, echo=FALSE}
get_regression_points(satm_mod1) %>% 
  select(-dollars) %>% 
  head(n=8) %>% 
  kable(format = 'html')
```
]

---
# OLS

```{r, echo=FALSE}
satm_mod1_points <- get_regression_points(satm_mod1) %>% 
  mutate(sq_resid = residual^2)

head(satm_mod1_points, n=4) %>% 
  kable(format = 'html')
```

```{r}
sum(satm_mod1_points$sq_resid)
```

- No other line will achieve a sum of squared residuals less than 45,727

---
class: inverse, middle, center

# But how good is the best?

---
# Goodness-of-fit

- When we ask how good is our best regression line, one way to answer is the **percent of total variation/variance in the outcome that is explained by our model**

--

- $R^2$ (r-squared)
  - Ranges from 0 to 1
  - The percent of variation in $y$ explained by our regression model

---
# Goodness of fit

- Model 1 using `dollars`

```{r, eval=FALSE}
get_regression_summaries(satm_mod1)
```

```{r, echo=FALSE}
get_regression_summaries(satm_mod1) %>%
  select(r_squared, adj_r_squared, rmse, sigma) %>% 
  kable(format = 'html')
```

The regression using dollars explains 24% of total variation in average SAT math scores.

---
# Goodness of fit

- Model 2 using `percent`

```{r, eval=FALSE}
get_regression_summaries(satm_mod2)
```

```{r, echo=FALSE}
get_regression_summaries(satm_mod2) %>%
  select(r_squared, adj_r_squared, rmse, sigma) %>% 
  kable(format = 'html')
```

- What percent of variation in average SAT math scores is explained by model 2?

--

- 74%

--

- Model 2 has the highest $R^2$. It is *statistically* superior.

---
# Goodness of fit

.pull-left[
```{r, echo=FALSE, message=FALSE, fig.align='center'}
ggplot(States, aes(x = dollars, y = SATM)) +
  geom_point() +
  geom_smooth(method = 'lm', se = FALSE) +
  labs(x = 'Public ed spending in $1000s per student',
       y = 'Average SAT Math score')
```
]

.pull-right[
```{r, echo=FALSE, message=FALSE, fig.align='center'}
ggplot(States, aes(x = percent, y = SATM)) +
  geom_point() +
  geom_smooth(method = 'lm', se = FALSE) +
  labs(x = 'Percent high school graduates taking SAT',
       y = 'Average SAT Math score')
```
]

---
# Goodness of fit

- $R^2$ isn't very useful for a general audience and it has limited practical application for predictions.

--

- Root mean squared error (**RMSE**) answers the question: "How far off is our model, on average, from observed outcomes? If we predict an outcome, what is the typical range of inaccuracy?

--

- RMSE is the regression version of standard deviation; provides the average deviation from the regression line

- The lower the RMSE the better our model is at fitting the data

---
# Goodness of fit
Model 1 using dollars
```{r, echo=FALSE}
get_regression_summaries(satm_mod1) %>%
  select(r_squared, adj_r_squared, rmse, sigma) %>% 
  kable(format = 'html')
```

Model 2 using percent
```{r, echo=FALSE}
get_regression_summaries(satm_mod2) %>%
  select(r_squared, adj_r_squared, rmse, sigma) %>% 
  kable(format = 'html')
```

--

.pull-left[
- Model 1 predictions are off by about 30 points, on average.
- What about model 2?
]

--

.pull-right[
- Model 2 predictions are off by about 18 points, on average.
- Model 2 is the *statistically* superior model.
]

---
class: inverse, center, middle

# Multiple regression

---
# Multiple regression

- Multiple regression adds more than one explanatory variable to the model. 

--

**Population model**
$$y=\beta_0+\beta_1x_1+\beta_2x_2+\dots+\beta_kx_k+\epsilon$$

**Sample model**
$$\hat{y}=b_0+b_1x_1+b_2x_2+\dots+b_kx_k$$

--

- This isolates the association between the outcome and each explanatory variable, holding all other variables constant at their respective means.

---
# Controlling for other factors

- The two previous regressions each controlled for one variable we might theorize affects average state SAT math scores

--

- There is any number of additional variables contained in the error term $\epsilon$

--

- Typically, if we can, we should include those additional variables in the same regression model

- Especially if those variables affect the explanatory variables currently in our model

---
class: inverse, center, middle

# Importance of theory or subject-matter expertise

---
# Making sense of our results

- So far, states spending more on public education apparently tend to have lower SAT math scores; may seem counter-intuitive to some

--

- We also see that states with a higher percent of graduates taking the SAT tend to have lower SAT math scores

--

- What may be going on here?

---
# Making sense of our results

```{r, echo=FALSE, message=FALSE, fig.align='center'}
ggplot(States, aes(x = dollars, y = percent)) +
  geom_point() +
  geom_smooth(method = 'lm', se = FALSE) +
  labs(x = 'Public ed spending in $1000s per student',
       y = 'Percent of graduates taking SAT')
```

---
# Running multiple regression

$$SATM=\beta_0+\beta_1Dollars+\beta_2Percent+\epsilon$$

```{r}
satm_mod3 <- lm(SATM ~ dollars + percent, data = States)
```
```{r, eval=FALSE}
get_regression_table(satm_mod3)
```
```{r, echo=FALSE}
get_regression_table(satm_mod3) %>% 
  kable(format = 'html')
```

$$SATM=515+6.4 \times Dollars - 1.5 \times Percent+\epsilon$$

---
# Reporting results

$$SATM=515+6.4 \times Dollars - 1.5 \times Percent+\epsilon$$

On average, a one thousand dollar increase in spending per pupil is associated with 6.4 point increase in average SAT math scores, **controlling for the percent of students taking the SAT**.

--

- Blah, blah, blah, **all else equal**.

---
# Interpreting results

```{r, echo=FALSE}
get_regression_table(satm_mod3) %>% 
  kable(format = 'html')
```

$$SATM=515+6.4 \times Dollars - 1.5 \times Percent+\epsilon$$

- Controlling for the percent of graduates taking the SAT, what is the predicted change in SAT math scores if states increase public education spending by $5,000 per student?

---
# Interpreting results

```{r, echo=FALSE}
get_regression_table(satm_mod3) %>% 
  kable(format = 'html')
```

$$SATM=515+6.4 \times Dollars - 1.5 \times Percent+\epsilon$$

What is the predicted average SAT math score for a state that spends $5,000 per student, and has 50% of high school graduates take the SAT?

---
class: inverse, middle, center

# Connecting results to policy decisions

---
# Policy Decision

- We haven't covered enough material to know whether or how we should act on this information, but let's work with what we know so far

  - Let's ignore matters of inference
  
  - Let's assume these results are causal

--

- That said, so far:

  - Spending increases average SAT math scores among states, *controlling for percent of high school grads taking SAT*
  
  - But spending seems to increase the percent of SAT participation, which then decreases average SAT math scores

- Let's examine the effect of spending on SAT math scores

---
# Spending and SAT participation

```{r}
satm_mod4 <- lm(percent ~ dollars, data = States)
```

```{r, eval=FALSE}
get_regression_table(satm_mod4)
```

```{r, echo=FALSE}
get_regression_table(satm_mod4) %>% 
  kable(format = 'html')
```

- A $1,000 increase in spending per pupil increases the percent of grads taking the SAT by 12.4 *percentage points*.

---
# Policy Decision

- A $1,000 increase in spending per student:
  
  - Directly increases average SAT math scores 6.4 points
  
  - Directly increases participation 12.4 percentage points
  
  - Increase of 12.4 p.p. reduces average SAT math scores 18.6 points
  
- The total effect of a $1,000 increase on average SAT math scores is about -12.2 points. Same as first model.

--

- What should be our policy recommendation?

---
class: inverse, middle, center

# Goodness-of-fit with multiple regression

---
# Goodness-of-fit

**Model 2 using only percent**
```{r, echo=FALSE}
get_regression_summaries(satm_mod2) %>%
  select(r_squared, adj_r_squared, rmse, sigma) %>% 
  kable(format = 'html')
```

**Model 3 using dollars and percent**

```{r, echo=FALSE}
get_regression_summaries(satm_mod3) %>% 
  select(r_squared, adj_r_squared, mse, rmse, sigma) %>%
  kable(format = 'html')
```

- Based on $R^2$, model 3 appears to be the better model, however...

---
# Goodness of fit

- $R^2$ mechanically increases as you add more variables whether or not they improve the model

- Therefore, we should not use $R^2$ to compare models with different numbers of explanatory variables

--

- **Adjusted $R^2$ ** accounts for this, adjusting based on how useful each additional variable is at explaining the outcome

- Model 3 still has the higher adjusted $R^2$ so it remains the statistically better model

- And the RMSE agrees; virtually always the case