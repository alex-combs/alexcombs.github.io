---
title: "PADP 7120 Data Applications in PA"
subtitle: "Causation"
author: "Alex Combs"
institute: "UGA | SPIA | PADP"
date: "Last updated: `r format(Sys.time(), '%B %d, %Y')`"
output:
  xaringan::moon_reader:
    css: 'mypres.css'
    nature:
      beforeInit: "macros.js"
      highlightStyle: github
      countIncrementalSlides: false
---
# Outline

```{r, include=FALSE}
library(tidyverse)
library(moderndive)
library(knitr)
set.seed(123)
options(scipen = 999)
```

- Overview of research design and key components
  - Counterfactual
  - Internal validity
  - External validity
  - Experimental, quasi-experimental, non-experimental

- Criteria to claim that $x$ *causes* a change in $y$

- Systematic process to identify omitted variable bias (endogeneity) and what can be done about it

---
# Potential outcomes

- A causal effect is a comparison of two potential outcomes

--

- The outcome that we observe in the presence of the event

- The outcome that we would have observed had the event *not happened*

--

- What would have happened in this alternate reality is referred to as the **counterfactual**

---
# Potential outcomes

- Half of the data we need to *observe* causation is missing

- We observe the outcome for those who received some treatment

- We observe the outcome for those who did not receive the treatment

--

- Can never observe the outcome among the treated had they not received it or the untreated as if they had

---
# The challenge of counterfactual

- All we can do is compare outcomes between observed groups. This can take several forms.

--

- **Randomize** treatment so nothing else differs between treated and untreated groups

--
  
- Use **quasi-experimental** design that leverages some aspect of the treatment to claim it is *as if* randomized

--
  
- Control for the all the right variables between treated and untreated claiming nothing else differs between the two *as if* randomized

---
# Credible Analysis

```{r, echo=FALSE, fig.align='center'}
include_graphics('lectures_files/credible.png')
```

---
# Internal validity

**Internal validity:** the credibility of the theoretical assumptions applied and the causal connection established between the cause (policy, program, treatment) and an effect

- Does a change in $x$ cause a change in $y$?

---
# Criteria for causation

1. Correlation between $x$ and $y$ -- as $x$ changes, $y$ must also tend to change

2. Temporal precedence -- $x$ must occur before $y$

3. No plausible rival or alternative explanations -- no other variable $z$ can influence the change in $y$ we attribute to $x$

---
# Correlation between X and Y

- If you run a regression and the coefficient is statistically significant, you have established correlation that is unlikely random

- But many things correlate that share no causal relationship

---
# Temporal Precedence

- Easiest for discrete event or intervention

  - Medicaid expansion on health outcomes
  
  - Stimulus check on spending/saving
  
  - Job training program on employment outcomes

--
  
- More difficult with ongoing/continuous phenomena

  - Mask wearing and COVID spread
  
  - Macroeconomics
  
- Possible solution: Use $x$ from previous periods to explain current $y$

---
# No plausible alternative explanation

- No other variable $z$ can influence the change in $y$ we attribute to $x$

--

- Employment rate among those who participated in a job training program is 75% compared to 40% among those who did not participate.

--

- Conclusion: Job training programs increase the likelihood of employment by 35 percentage points. 

- Plausible alternatives?

---
class: inverse, center, middle

# Directed Acyclical Graphs (DAGS)

---
# DAGS

- Visual representation of causal pathways

- Forces us to consider our assumptions

- Allows for a systematic evaluation of causal model, especially using **observational**, **non-experimental** data

---
# Regression and DAGS

- Behind every regression is a DAG

$$Happiness=\beta_0+\beta_1Age+\beta_2Income+\epsilon$$

```{r, echo=FALSE, fig.align='center'}
include_graphics('lectures_files/dag15.png')
```

---
# Notation and Rules

.pull-left[

- Solid arrow: effect is observable
- Dashed arrow: effect is unobservable
- Arrows claim correlation, at least

- Two types of paths:
  - Direct $X \rightarrow Y$
  - Mediated (indirect) $X \rightarrow Z \rightarrow Y$

]

.pull-right[

```{r, echo=FALSE}
include_graphics('lectures_files/dag2.png')
```

- No two-way arrows
- No direct path from $Y$ back to $X$

]

---
# Our focus on DAGS

- Backdoor paths

- Adjusting for **confounding** and **colliding** variables

- Translating regression to DAGS and vice versa

- Further reading: Pearl, J. (2018). [The Book of Why](https://www.amazon.com/dp/B07CYJ4G2L/ref=cm_sw_em_r_mt_dp_QlXEFb2CK71MS)

---
# Backdoor path

```{r, echo=FALSE, fig.align='center', fig.height=5}
include_graphics('lectures_files/dag3.png', dpi = 100)
```

- $Z$ is a **confounder**

- Leads to **omitted variable bias** (OVB)

---
# Close the backdoor

- Our goal is to close all backdoor paths between $X$ and $Y$

- Three ways to close a backdoor path

--

1. Control for the **confounder** in our regression

---
# Close the backdoor

```{r, echo=FALSE, fig.align='center'}
include_graphics('lectures_files/dag4.png')
```

.pull-left[
$$Y=\beta_0+\beta_1X+\epsilon$$

- Backdoor open - OVB
]

.pull-right[
$$Y=\beta_0+\beta_1X+\beta_2Z+\epsilon$$

- Backdoor closed - No OVB
]

---
# Close the backdoor

- Three ways to close a backdoor path

1. Control for the **confounder**

--

2. Control for any variable along the backdoor path

---
# Close the backdoor

```{r, echo=FALSE, fig.align='center'}
include_graphics('lectures_files/dag4.2.png', dpi = 100)
```

.center[
$$X \rightarrow Y$$
$$X \leftarrow Z \rightarrow K \rightarrow Y$$
]

.pull-left[
$$Y=\beta_0+\beta_1X+\epsilon$$

- Backdoor open; OVB
]

.pull-right[
$$Y=\beta_0+\beta_1X+\beta_2K+\epsilon$$

- Backdoor closed/blocked; no OVB
]

---
# Close the backdoor

- Three ways to close a backdoor path

1. Control for the **confounder**

--

2. Control for any variable along the backdoor path

--

3. Identify a **collider** variable that closes the backdoor path

---
# Collider variable

```{r, echo=FALSE, fig.align='center'}
include_graphics('lectures_files/dag6.png', dpi = 100)
```

- $Z$ is a **collider** in this case

- Colliders close backdoors

---
# Close the backdoor

```{r, echo=FALSE, fig.align='center'}
include_graphics('lectures_files/dag5.png', dpi = 140)
```

.center[
$X \rightarrow Y$

$X \leftarrow Z \rightarrow K \leftarrow Y$
]

.pull-left[
$$Y=\beta_0+\beta_1X+\epsilon$$
$$Y=\beta_0+\beta_1X+\beta_2Z+\epsilon$$
$$Y=\beta_0+\beta_1X+\beta_2Z+\beta_3K+\epsilon$$
- All are fine; backdoor closed
]

.pull-right[
$$Y=\beta_0+\beta_1X+\beta_2K+\epsilon$$

- Backdoor open; OVB

- **Controlling for a collider opens the backdoor it closed**
]

---
# The error term and OVB

```{r, echo=FALSE, fig.align='center'}
include_graphics('lectures_files/dag8.png', dpi = 100)
```

.center[

$$Y=\beta_0+\beta_1X+\epsilon$$

]

- If true model was left DAG, our estimate $b_1$ is *not* solely due to $X$, but rather unobserved factors contained in $\epsilon$

- Referred to as **endogeneity** or "X is endogenous"

---
# Error term and OVB

.center[
$$Happiness=\beta_0+\beta_1Age+\beta_2Income+\epsilon$$]

.pull-left[
```{r, echo=FALSE, fig.align='center'}
include_graphics('lectures_files/dag15.png')
```
]

.pull-right[
- What variables might the error term contain?

- Do any of our omitted variables also affect age or income?
]

---
class: inverse, center, middle

# Using DAGS systematically

---
# Using DAGS

1. Begin with the direct path between $X$ and $Y$ based on your research question

2. Identify other factors that affect $X$ and/or $Y$, adding them to the DAG accordingly

3. List all paths starting from $X$ to $Y$

4. Identify any backdoor paths and determine how to close them

---
# Using DAGS

- Suppose we want to know if college, $C$, increases earnings, $Y$?

- $C \rightarrow Y$

$$Y=\beta_0+\beta_1C+\epsilon$$

--

- Now we should think of all the factors that affect earnings and/or going to college

- Suppose we identify three factors: 
  - Parent's education $PE$ 
  - Family income $I$ 
  - Natural aptitude of parents/child $A$

---
# Using DAGS

- Now we think of the relationships between all of our factors and draw the corresponding DAG

- Suppose we settle on the following DAG

```{r, echo=FALSE, fig.align='center'}
include_graphics('lectures_files/dag10.png', dpi = 125)
```

- Next step is to list paths between $C$ and $Y$

---
# Using DAGS

```{r, echo=FALSE, fig.align='center'}
include_graphics('lectures_files/dag10.png', dpi = 150)
```

1. $C \rightarrow Y$ (the causal effect of college on earnings)

--

2. $C \leftarrow I \rightarrow Y$ (backdoor 1)

--

3. $C \leftarrow PE \rightarrow I \rightarrow Y$ (backdoor 2)

--

4. $C \leftarrow A \rightarrow PE \rightarrow I \rightarrow Y$ (backdoor3)

--

- Any colliders? No. We have three open backdoor paths. Systematic non-causal correlations between $C$ and $Y$

---
# Using DAGS

1. $C \rightarrow Y$ (the causal effect of college on earnings)
2. $C \leftarrow I \rightarrow Y$ (backdoor 1)
3. $C \leftarrow PE \rightarrow I \rightarrow Y$ (backdoor 2)
4. $C \leftarrow A \rightarrow PE \rightarrow I \rightarrow Y$ (backdoor3)

- Next step is to identify the minimum set of control variables needed to close all backdoors.

--

- Controlling for family income $I$ closes all three backdoors

.center[
$$Y=\beta_0+\beta_1C+\beta_2I+\epsilon$$
]

- If we believe this DAG, then we now have the causal effect of college on earnings.

---
# Assumptions & alternatives

```{r, echo=FALSE, fig.align='center'}
include_graphics('lectures_files/dag10.png', dpi = 150)
```

- Two key assumptions this DAG makes

--

1. Other than natural aptitude $A$, no other *unobserved* factors affect $C$

--

2. Natural aptitude does not directly affect earnings $Y$

---
# Assumptions & alternatives

```{r, echo=FALSE, fig.align='center'}
include_graphics('lectures_files/dag11.png', dpi = 150)
```

--

.pull-left[
1. $C \rightarrow Y$ 
2. $C \leftarrow I \rightarrow Y$ 
3. $C \leftarrow PE \rightarrow I \rightarrow Y$
4. $C \leftarrow A \rightarrow PE \rightarrow I \rightarrow Y$ 
5. $C \leftarrow A \rightarrow Y$
6. $C \leftarrow PE \leftarrow A \rightarrow Y$
7. $C \leftarrow I \leftarrow PE \leftarrow A \rightarrow Y$
]

.pull-right[

- Controlling for $I$ closes 2, 3, 4, & 7

- Controlling for $PE$ closes 6

- Currently no way to close 5; our causal hopes are dashed
]

---
class: inverse, center, middle

# Let's practice using DAGs in groups

---
class: inverse, center, middle

# Collider Bias Revisited

---
# Collider bias

- Collider bias can occur in two ways:

- Controlling for a collider in our regression in a way that opens a backdoor path that would have been closed

- Using a sample where observations are based on a collider variable

---
# Collider bias: bad control

```{r, echo=FALSE, fig.align='center'}
include_graphics('lectures_files/dag12.png', dpi = 150)
```

1. $Marijuana \rightarrow CarAcc$
2. $Marijuana \leftarrow Norms \rightarrow Seatbelt \leftarrow Safety \rightarrow CarAcc$


$$CarAcc = \beta_0 + \beta_1Marijuana + \beta_2Seatbelt + \epsilon$$

- Controlling for seatbelt usage would introduce bias


---
# Seeing collider bias

- Creating a dataset with 2500 observations and 3 variables drawn randomly from a normal distribution

```{r}
collider_bias <- data.frame(k = rnorm(2500, mean = 10, sd = 4), 
                            e = rnorm(2500), 
                            u = rnorm(2500))
```

```{r, echo=FALSE}
head(collider_bias, n = 4) %>% 
  kable(digits = 2)
```

---
# Seeing collider bias

- Adding the explanatory variable of interest $X$ equal to 1 when $k$ is greater than or equal to 12 (arbitrary choice)

```{r}
collider_bias <- collider_bias %>% 
  mutate(X = if_else( k >= 12, 1, 0))
```

--

- Creating a known parameter for the effect of $X$ on $Y$. 

```{r}
collider_bias <- collider_bias %>% 
  mutate(Y = 100 + 50*X + e)
```

--

- Creating a collider $Z$ that is a function of $X$ and $Y$. $Y$ **is not** a function of $Z$.

```{r}
collider_bias <- collider_bias %>% 
  mutate(Z = 50*X + Y + u)
```

---
# Seeing collider bias

- Now have the data we need to run two regressions

```{r, echo=FALSE}
head(collider_bias, n = 4) %>% 
  kable(digits = 2)
```

$$Y=\beta_0 + \beta_1X + \epsilon$$

$$Y=\beta_0 + \beta_1X + \beta_2Z + \epsilon$$

```{r}
valid <- lm(Y ~ X, data = collider_bias)
biased <- lm(Y ~ X + Z, data = collider_bias)
```

---
# Seeing collider bias

.pull-left[
```{r, echo=FALSE}
get_regression_table(valid) %>% 
  select(term, estimate) %>% 
  kable(digits = 2)
```
]

.pull-right[
```{r, echo=FALSE}
get_regression_table(biased) %>% 
  select(term, estimate) %>% 
  kable(digits = 2)
```
]

- Coefficient for $X$ should be 50 because I made it so.

- Because $X \rightarrow Z \leftarrow Y$, controlling for Z introduces serious bias

---
# Collider bias: bad sample

- Suppose a nonprofit that works with at-risk youth wants to understand the effect of school absences on grades. It only has access to data on its own clients.

- Suppose at-risk youth are identified by socioeconomic status, GPA, and absences

```{r, echo=FALSE, fig.align='center'}
include_graphics('lectures_files/dag13.png', dpi = 150)
```

---
# Collider bias (2) bad sample

$$GPA = \beta_0 + \beta_1TotAbsences + \beta_2 SES + \epsilon$$

```{r, echo=FALSE, fig.align='center'}
include_graphics('lectures_files/dag13.png', dpi = 150)
```

.pull-left[

1. $TA \rightarrow GPA$
2. $TA \leftarrow SES \rightarrow GPA$
3. $TA \rightarrow AtRisk \leftarrow GPA$
4. $TA \leftarrow SES \rightarrow AtRisk \leftarrow GPA$

]

.pull-right[

- Will our estimate $b_1$ be unbiased?

- No. Because our sample is selected from $AtRisk$; same as controlling for it.

- Selection bias
]

---
# Seeing selection bias

$Absent \rightarrow AtRisk \leftarrow GPA$

- Suppose our sample only includes those at-risk

- But we want to estimate the effect of absences on GPA

```{r, include=FALSE}
selection_bias <- data.frame(absent = rnorm(2500, 8, 2), 
                             gpa = rnorm(2500, 2.5, 0.45))

selection_bias <- mutate(selection_bias, score = (absent + 3*gpa))

quantile(selection_bias$score, 0.2)
selection_bias <- mutate(selection_bias, at_risk = if_else(score <= 13.423, 1, 0))
```


---
# Seeing selection bias

.pull-left[

```{r, echo=FALSE, message=FALSE}
selection_bias %>% 
  filter(at_risk == 1) %>% 
  ggplot(aes(x = absent, y = gpa)) +
  geom_point(alpha = 0.4) +
  geom_smooth(method = "lm", se = FALSE) + 
  labs(title = 'Effect of absences on GPA',
       subtitle = 'Sample of At-Risk Students') +
  theme_minimal()
```

]

.pull-right[

```{r, echo=FALSE}
selbias_risk <- selection_bias %>% 
  filter(at_risk == 1)

atrisk_mod <- lm(gpa ~ absent, selbias_risk)

get_regression_table(atrisk_mod) %>% 
  select(term, estimate) %>% 
  kable(digits = 3)
```

]

---
# Seeing selection bias

.pull-left[

```{r, echo=FALSE, message=FALSE}
selection_bias %>% 
  filter(at_risk == 0) %>% 
  ggplot(aes(x = absent, y = gpa)) +
  geom_point(alpha = 0.4) +
  geom_smooth(method = "lm", se = FALSE) + 
  labs(title = 'Effect of absences on GPA',
       subtitle = 'Sample of Students Not At-Risk') +
  theme_minimal()
```

]

.pull-right[

```{r, echo=FALSE}
selbias_norisk <- selection_bias %>% 
  filter(at_risk == 0)

norisk_mod <- lm(gpa ~ absent, selbias_norisk)

get_regression_table(norisk_mod) %>% 
  select(term, estimate) %>% 
  kable(digits = 3)
```

]

---
# Seeing selection bias

.pull-left[

```{r, echo=FALSE, message=FALSE}
selection_bias %>% 
  ggplot(aes(x = absent, y = gpa)) +
  geom_point(alpha = 0.4) +
  geom_smooth(method = "lm", se = FALSE) + 
  labs(title = 'Effect of absences on GPA',
       subtitle = 'All Students') +
  theme_minimal()
```

]

.pull-right[

```{r, echo=FALSE}
allstud_mod <- lm(gpa ~ absent, selection_bias)

get_regression_table(allstud_mod) %>% 
  select(term, estimate) %>% 
  kable(digits = 3)
```

]

---
# Seeing Selection Bias

```{r, echo=FALSE, fig.align='center', out.height='90%', message=FALSE}
selection_bias %>% 
  ggplot(aes(x = absent, y = gpa)) +
  geom_point(aes(x = absent, y = gpa, color = as.factor(at_risk)), alpha = 0.4) +
  geom_smooth(method = "lm", se = FALSE) +
  geom_smooth(aes(x = absent, y = gpa, color = as.factor(at_risk)), method = "lm", se = FALSE) +
  labs(color = "At-Risk") +
  theme_minimal()
```


---
# Recap

- What would be the ideal experiment and how does my analysis differ?

--

- Can I convincingly claim there is no OVB?

--

- If so, internally valid. Now we can consider **external validity**.

---
# External validity

- **External validity (generalizability):** can results of research be applied beyond the groups or context being studied?

--

- Are those in my sample systematically different than those in my intended population?

- Probably, but if not, can generalize to population.

--

- If different, was my sample drawn from a collider?

  - Yes. Then all backdoors are not closed.
  - No. Then may be able to generalize to the subgroup my sample represents.

---
# Causal inference models

```{r, echo=FALSE, fig.align='center'}
include_graphics('lectures_files/dag14.png', dpi = 150)
```

- Random assignment breaks any OVB from the error term

- Random assignment is often difficult to achieve in social sciences

- There are quasi-experimental regression techniques that arguably achieve the same break from the error term as if random
  - Difference-in-differences, regression discontinuity, instrumental variables, synthetic control, fixed effects, propensity score matching
